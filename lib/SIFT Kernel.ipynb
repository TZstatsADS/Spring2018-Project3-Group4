{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract keypoints from each image\n",
    "To do it, we will use OpenCV (cv2) library to extract keypoints with SIFT algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "img_path = os.path.expanduser(\"~\\Documents\\GitHub\\Spring2018-Project3-Group4\\data\\\\train\\images\")\n",
    "label_path=os.path.expanduser(\"~\\Documents\\GitHub\\Spring2018-Project3-Group4\\data\\\\train\\label_train.csv\")\n",
    "file_path=os.path.expanduser(\"~\\Documents\\GitHub\\Spring2018-Project3-Group4\\data\\\\train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = train.label.sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sift features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sift=cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thispic=\"0001\"\n",
    "img = cv2.imread(img_path +\"\\\\\"+ str(thispic).replace(\"img_\",\"\") + \".jpg\")\n",
    "kp, des = sift.detectAndCompute(img, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(695, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238, 300, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dico = []\n",
    "for pic in train.img:\n",
    "    img = cv2.imread(img_path +\"\\\\\"+ str(pic).replace(\"img_\",\"\") + \".jpg\")\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    dico.append(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wesle\\AppData\\Local\\Temp\\tmpmnys6k26\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tempfile as tf\n",
    "tmp = tf.NamedTemporaryFile().name\n",
    "print(tmp)\n",
    "with open(tmp,\"bw\") as f:\n",
    "    pickle.dump(dico,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surf = cv2.xfeatures2d.SURF_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kp2,des2=surf.detectAndCompute(img,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dico2 = []\n",
    "for pic in train.img:\n",
    "    img = cv2.imread(img_path +\"\\\\\"+ str(pic).replace(\"img_\",\"\") + \".jpg\")\n",
    "    kp, des = surf.detectAndCompute(img, None)\n",
    "    dico2.append(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wesle\\AppData\\Local\\Temp\\tmpe5mvdhxa\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tempfile as tf\n",
    "tmp = tf.NamedTemporaryFile().name\n",
    "print(tmp)\n",
    "with open(tmp,\"bw\") as f:\n",
    "    pickle.dump(dico2,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.9161565e-03, -2.6855809e-03,  4.3385481e-03,  7.4099726e-03,\n",
       "        2.5397781e-02, -1.7121205e-02,  2.9150501e-02,  4.4253193e-02,\n",
       "        1.5377193e-02,  2.7369496e-03,  1.7331593e-02,  1.1454537e-02,\n",
       "       -2.8572744e-04, -4.0021268e-04,  8.1149663e-04,  8.1667904e-04,\n",
       "       -2.7474711e-02, -4.3566092e-03,  3.5456143e-02,  2.5786242e-02,\n",
       "       -3.5054332e-03, -2.2787082e-01,  2.5501838e-01,  3.0258811e-01,\n",
       "        2.6765642e-01, -2.4544679e-01,  2.7449548e-01,  2.5497624e-01,\n",
       "       -1.3008570e-04, -7.3826802e-04,  4.5595104e-03,  5.4140827e-03,\n",
       "       -1.7316284e-02,  1.1169009e-02,  2.0835027e-02,  3.3596098e-02,\n",
       "       -1.7551915e-01,  7.7822693e-02,  2.7221686e-01,  2.0537888e-01,\n",
       "        4.0207654e-01,  3.0628642e-02,  4.0207654e-01,  1.5284283e-01,\n",
       "        5.2208952e-03, -1.0202182e-03,  5.5961590e-03,  2.3190069e-03,\n",
       "        2.7198475e-03, -2.1799174e-03,  5.7535055e-03,  6.4058257e-03,\n",
       "       -2.3220684e-02, -3.1941734e-02,  2.7600804e-02,  3.3767216e-02,\n",
       "        5.2569740e-02, -1.5777593e-03,  5.2569740e-02,  6.8023056e-03,\n",
       "        1.5413184e-03, -2.8810833e-04,  1.7456517e-03,  3.6297957e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orb=cv2.ORB_create()\n",
    "kp4,des4=orb.detectAndCompute(img,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dico3 = []\n",
    "for pic in train.img:\n",
    "    img = cv2.imread(img_path +\"\\\\\"+ str(pic).replace(\"img_\",\"\") + \".jpg\")\n",
    "    kp, des = surf.detectAndCompute(img, None)\n",
    "    dico3.append(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wesle\\AppData\\Local\\Temp\\tmpk1b2u3__\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tempfile as tf\n",
    "tmp = tf.NamedTemporaryFile().name\n",
    "print(tmp)\n",
    "with open(tmp,\"bw\") as f:\n",
    "    pickle.dump(dico3,f)# C:\\Users\\Wesle\\AppData\\Local\\Temp\\tmpk1b2u3__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sift feature k-means training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the histograms\n",
    "To create our each image by a histogram. We will create a vector of k value for each image. For each keypoints in an image, we will find the nearest center and increase by one its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"C:/Users/Wesle/AppData/Local/Temp/tmpmnys6k26\",\"br\") as f:\n",
    "        dico=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 2000\n",
    "kdico=np.concatenate(dico[:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisbatch_size = np.size(os.listdir(img_path)) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=k, batch_size=thisbatch_size, verbose=0).fit(kdico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histo_list=[]\n",
    "for eachdes in dico:\n",
    "    histo=np.zeros(k)\n",
    "    for d in eachdes:\n",
    "        idx=kmeans.predict([d])\n",
    "        nkp=eachdes.shape[0]\n",
    "        histo[idx] +=1/nkp\n",
    "    histo_list.append(histo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 128)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdico[0:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1915"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kindex[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 128)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico[6].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB feature kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "import os\n",
    "orbpath=\"C:/Users/Wesle/AppData/Local/Temp/tmpk1b2u3__\"\n",
    "with open(orbpath,\"br\") as f:\n",
    "    orbdico=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HistBuilding(thisdico):  \n",
    "    thiskdico=np.concatenate(thisdico[:],axis=0)\n",
    "    k=2000# total cluster\n",
    "    thisbatch_size = np.size(os.listdir(img_path)) * 3 #  batch size \n",
    "    kmeans = MiniBatchKMeans(n_clusters=k, batch_size=thisbatch_size, verbose=0).fit(thiskdico)\n",
    "    histo_list=[]\n",
    "    for eachdes in thisdico:\n",
    "        histo=np.zeros(k)\n",
    "        for d in eachdes:\n",
    "            idx=kmeans.predict([d])\n",
    "            nkp=eachdes.shape[0]\n",
    "            histo[idx] +=1/nkp\n",
    "        histo_list.append(histo)\n",
    "    return histo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orbfeature=HistBuilding(orbdico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA \n",
    "dimension reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wesle\\AppData\\Local\\Temp\\tmpvxotxrd5\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tempfile as tf\n",
    "tmp = tf.NamedTemporaryFile().name\n",
    "print(tmp)\n",
    "with open(tmp,\"bw\") as f:\n",
    "    pickle.dump(histo_list,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histo_list.__len__()\n",
    "histo_list[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
